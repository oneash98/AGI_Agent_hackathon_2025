import json
import requests
from bs4 import BeautifulSoup
from langchain_upstage import ChatUpstage
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import base64, json
from openai import OpenAI
from scipy.spatial import KDTree
import numpy as np

def encode_image_to_base64(path):
    with open(path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")

def return_json(API_KEY, file_path):
    schema_client = OpenAI(api_key=API_KEY, base_url="https://api.upstage.ai/v1/information-extraction/schema-generation")
    # Encode the image
    encoded_image = encode_image_to_base64(file_path)
    
    schema_response = schema_client.chat.completions.create(
        model="information-extract",
        messages=[{"role": "user", "content": [
            {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{encoded_image}"}}
        ]}],
    )
    # Define your schema (or use a pre-generated one)
    schema = {
        "type": "json_schema",
        "json_schema": {
            "name": "document_schema",
            "schema": {
                "type": "object",
                "properties": {
                    "í‚¤": {
                        "type": "number",
                        "description": "í‚¤ (cm)"
                    },
                    "ëª¸ë¬´ê²Œ": {
                        "type": "number",
                        "description": "ëª¸ë¬´ê²Œ (kg)"
                    },
                    "ì²´ì§ˆëŸ‰ì§€ìˆ˜": {
                        "type": "number",
                        "description": "ì²´ì§ˆëŸ‰ì§€ìˆ˜ (kg/ã¡)"
                    },
                    "í—ˆë¦¬ë‘˜ë ˆ": {
                        "type": "number",
                        "description": "í—ˆë¦¬ë‘˜ë ˆ (cm)"
                    },
                    "í˜ˆì••": {
                        "type": "string",
                        "description": "í˜ˆì•• (ìˆ˜ì¶•ê¸°/ì´ì™„ê¸°, mmHg)"
                    },
                    "í˜ˆìƒ‰ì†Œ": {
                        "type": "string",
                        "description": "ë¹ˆí˜ˆ ë“± í˜ˆìƒ‰ì†Œ (g/dL)"
                    },
                    "ë¹ˆí˜ˆ ì†Œê²¬": {
                        "type": "string",
                        "description": "ì •ìƒ/ë¹ˆí˜ˆ ì˜ì‹¬/ê¸°íƒ€ ì¤‘ ì²´í¬ëœ í•­ëª©"
                    },
                    "ê³µë³µí˜ˆë‹¹": {
                        "type": "string",
                        "description": "ë‹¹ë‡¨ë³‘ ê³µë³µí˜ˆë‹¹ (mg/dL)"
                    },
                    "ë‹¹ë‡¨ë³‘ ì†Œê²¬": {
                        "type": "string",
                        "description": "ì •ìƒ/ê³µë³µí˜ˆë‹¹ì¥ì•  ì˜ì‹¬/ìœ ì§ˆí™˜ì/ë‹¹ë‡¨ë³‘ ì˜ì‹¬ ì¤‘ ì²´í¬ëœ í•­ëª©"
                    },
                    "ì´ì½œë ˆìŠ¤í…Œë¡¤": {
                        "type": "string",
                        "description": "ì´ì½œë ˆìŠ¤í…Œë¡¤ (mg/dL)"
                    },
                    "ê³ ë°€ë„ì½œë ˆìŠ¤í…Œë¡¤": {
                        "type": "string",
                        "description": "ê³ ë°€ë„ ì½œë ˆìŠ¤í…Œë¡¤ (mg/dL)"
                    },
                    "ì¤‘ì„±ì§€ë°©": {
                        "type": "string",
                        "description": "ì¤‘ì„±ì§€ë°© (mg/dL)"
                    },
                    "ì €ë°€ë„ì½œë ˆìŠ¤í…Œë¡¤": {
                        "type": "string",
                        "description": "ì €ë°€ë„ ì½œë ˆìŠ¤í…Œë¡¤ (mg/dL)"
                    },
                    "ì´ìƒì§€ì§ˆí˜ˆì¦ ì†Œê²¬": {
                        "type": "string",
                        "description": "ì •ìƒ/ê³ ì½œë ˆìŠ¤í…Œë¡¤í˜ˆì¦ ì˜ì‹¬/ê³ ì¤‘ì„±ì§€ë°©í˜ˆì¦ ì˜ì‹¬/ë‚®ì€ HDL ì½œë ˆìŠ¤í…Œë¡¤ ì˜ì‹¬/ìœ ì§ˆí™˜ì ì¤‘ ì²´í¬ëœ í•­ëª©"
                    },
                    "í˜ˆì²­í¬ë ˆì•„í‹°ë‹Œ": {
                        "type": "string",
                        "description": "í˜ˆì²­ í¬ë ˆì•„í‹°ë‹Œ (mg/dL)"
                    },
                    "eGFR": {
                        "type": "string",
                        "description": "ì‹ ì‚¬êµ¬ì²´ì—¬ê³¼ìœ¨ (mL/min/1.73ã¡)"
                    },
                    "ì‹ ì¥ì§ˆí™˜ ì†Œê²¬": {
                        "type": "string",
                        "description": "ì •ìƒ/ì‹ ì¥ê¸°ëŠ¥ ì´ìƒ ì˜ì‹¬ ì¤‘ ì²´í¬ëœ í•­ëª©"
                    },
                    "AST": {
                        "type": "string",
                        "description": "AST (SGOT) (IU/L)"
                    },
                    "ALT": {
                        "type": "string",
                        "description": "ALT (SGPT) (IU/L)"
                    },
                    "ê°ë§ˆì§€í‹°í”¼": {
                        "type": "string",
                        "description": "ê°ë§ˆì§€í‹°í”¼ (Î³GTP) (IU/L)"
                    },
                    "ê°„ì¥ì§ˆí™˜": {
                        "type": "string",
                        "description": "ì •ìƒ/ê°„ê¸°ëŠ¥ ì´ìƒ ì˜ì‹¬ ì¤‘ ì²´í¬ëœ í•­ëª©"
                    },
                    "ìš”ë‹¨ë°±": {
                        "type": "string",
                        "description": "ì •ìƒ/ê²½ê³„/ë‹¨ë°±ë‡¨ ì˜ì‹¬ ì¤‘ ì²´í¬ëœ í•­ëª©"
                    },
                    "í‰ë¶€ì´¬ì˜": {
                        "type": "string",
                        "description": "ì •ìƒ/ë¹„í™œë™ì„± íê²°í•µ/íŠ¹ì • ì§ˆí™˜ ì˜ì‹¬/ê¸°íƒ€ ì†Œê²¬ ì¤‘ ì²´í¬ëœ í•­ëª©"
                    },
                    "ê³¼ê±°ë³‘ë ¥": {
                        "type": "string",
                        "description": "ê³¼ê±°ë³‘ë ¥ (ì˜ˆ: ì—†ìŒ)"
                    },
                    "ì•½ë¬¼ì¹˜ë£Œë³‘ë ¥": {
                        "type": "string",
                        "description": "ì•½ë¬¼ì¹˜ë£Œë³‘ë ¥ (ì˜ˆ: ì—†ìŒ)"
                    }
                },
                "required": [
                "í‚¤",
                "ëª¸ë¬´ê²Œ",
                "ì²´ì§ˆëŸ‰ì§€ìˆ˜",
                "í—ˆë¦¬ë‘˜ë ˆ",
                "í˜ˆì••",
                "í˜ˆìƒ‰ì†Œ",
                "ë¹ˆí˜ˆ ì†Œê²¬",
                "ê³µë³µí˜ˆë‹¹",
                "ë‹¹ë‡¨ë³‘ ì†Œê²¬",
                "ì´ì½œë ˆìŠ¤í…Œë¡¤",
                "ê³ ë°€ë„ì½œë ˆìŠ¤í…Œë¡¤",
                "ì¤‘ì„±ì§€ë°©",
                "ì €ë°€ë„ì½œë ˆìŠ¤í…Œë¡¤",
                "ì´ìƒì§€ì§ˆí˜ˆì¦ ì†Œê²¬",
                "í˜ˆì²­í¬ë ˆì•„í‹°ë‹Œ",
                "eGFR",
                "ì‹ ì¥ì§ˆí™˜ ì†Œê²¬",
                "AST",
                "ALT",
                "ê°ë§ˆì§€í‹°í”¼",
                "ê°„ì¥ì§ˆí™˜",
                "ìš”ë‹¨ë°±",
                "í‰ë¶€ì´¬ì˜",
                "ê³¼ê±°ë³‘ë ¥",
                "ì•½ë¬¼ì¹˜ë£Œë³‘ë ¥"
                ]
            }
        }
    }
    
    # --- Step 2: Extract Information ---
    extract_client = OpenAI(api_key=API_KEY, base_url="https://api.upstage.ai/v1/information-extraction")
    extraction_response = extract_client.chat.completions.create(
        model="information-extract",
        messages=[{"role": "user", "content": [
            {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{encoded_image}"}}
        ]}],
        response_format=schema  # Use the auto-generated schema
    )

    # --- Step 3: Print or process the result ---
    extracted_data = json.loads(extraction_response.choices[0].message.content)
    return extracted_data

# upstage request ì˜¤ë¥˜ í™•ì¸
def print_upstage_error(response):
    if 'error' in response.json().keys():
        return response.json()['error']

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_function(API_KEY, file_path):

    url = "https://api.upstage.ai/v1/document-digitization"
    headers = {"Authorization": f"Bearer {API_KEY}"}
    files = {"document": open(file_path, "rb")}
    data = {"ocr": "force", "base64_encoding": "['table']", "model": "document-parse"}
    response = requests.post(url, headers=headers, files=files, data=data)

    # upstage ì˜¤ë¥˜ í™•ì¸
    upstage_error = print_upstage_error(response)
    if upstage_error:
        return upstage_error
    
    # ë©”ì¸ ê¸°ëŠ¥
    contents_html = response.json()['content']['html']
    soup = BeautifulSoup(contents_html)
    text = soup.find(attrs = {'id': '20'}).text

    return text



# ê°œë°œìš© ì˜ˆì‹œ ë°ì´í„°
test_data = """
{
"ë‚˜ì´": 30ëŒ€,
"ë³„ëª…": ê±´ê°•í•œë‹¤ëŒì¥,
"ì„±ë³„": ì—¬ì„±,
"í‚¤": 158,
"ëª¸ë¬´ê²Œ": 65.4,
"ì²´ì§ˆëŸ‰ì§€ìˆ˜": 26.2,
"í—ˆë¦¬ë‘˜ë ˆ": 86.0,
"í˜ˆì••": "135/88 mmHg",
"í˜ˆìƒ‰ì†Œ": "12.6",
"ë¹ˆí˜ˆ ì†Œê²¬": "ì •ìƒ",
"ê³µë³µí˜ˆë‹¹": "108",
"ë‹¹ë‡¨ë³‘ ì†Œê²¬": "ê³µë³µí˜ˆë‹¹ì¥ì•  ì˜ì‹¬",
"ì´ì½œë ˆìŠ¤í…Œë¡¤": "198",
"ê³ ë°€ë„ì½œë ˆìŠ¤í…Œë¡¤": "55",
"ì¤‘ì„±ì§€ë°©": "140",
"ì €ë°€ë„ì½œë ˆìŠ¤í…Œë¡¤": "115",
"ì´ìƒì§€ì§ˆí˜ˆì¦ ì†Œê²¬": "ì •ìƒ",
"í˜ˆì²­í¬ë ˆì•„í‹°ë‹Œ": "1.5",
"eGFR": "48",
"ì‹ ì¥ì§ˆí™˜ ì†Œê²¬": "ë§Œì„± ì‹ ì¥ë³‘ ì˜ì‹¬",
"AST": "55",
"ALT": "62",
"ê°ë§ˆì§€í‹°í”¼": "85",
"ê°„ì¥ì§ˆí™˜": "ì§€ì†ì  ê°„ê¸°ëŠ¥ ì´ìƒ",
"ìš”ë‹¨ë°±": "ì–‘ì„±(1+)",
"í‰ë¶€ì´¬ì˜": "ì •ìƒ"
}
"""
test_data2 = """
- **í™˜ì ê¸°ë³¸ ì •ë³´**: 1966ë…„ìƒ ì—¬ì„±, 2025ë…„ 6ì›” 12ì¼ ê¸°ì¤€ ë§Œ 58ì„¸

- **ì˜ë¬´ê¸°ë¡ ì „ë¬¸**:

í™˜ìëŠ” 2025ë…„ 6ì›” 12ì¼ ì‹œí–‰í•œ ê±´ê°•ê²€ì§„ ìƒ ì‹ ì¥ê¸°ëŠ¥ ì €í•˜ ë° ê°„ê¸°ëŠ¥ ì´ìƒ ì†Œê²¬ì„ ë³´ì„.  

1. **ì²´ê²© ë° ì‹ ì²´ ê³„ì¸¡**
   - í‚¤ 158 cm, ëª¸ë¬´ê²Œ 65.4 kg, ì²´ì§ˆëŸ‰ì§€ìˆ˜(BMI) 26.2 kg/mÂ²ë¡œ ê³¼ì²´ì¤‘ ë²”ì£¼(25.0â€“29.9)ì— í•´ë‹¹.
   - í—ˆë¦¬ë‘˜ë ˆ 86.0 cmë¡œ ë³µë¶€ë¹„ë§Œ ê¸°ì¤€(ì—¬ì„± 85 cm ì´ìƒ)ì— ë¯¸ë‹¬.

2. **ëŒ€ì‚¬ê³„ ê²€ì‚¬**
   - ê³µë³µí˜ˆë‹¹ 108 mg/dLë¡œ ê³µë³µí˜ˆë‹¹ì¥ì• (IFG: 100â€“125 mg/dL) ë²”ì£¼ì´ë©°, ë‹¹ë‡¨ë³‘ ì „ë‹¨ê³„ì— í•´ë‹¹í•¨.
   - ì§€ì§ˆ í”„ë¡œíŒŒì¼:
     - ì´ì½œë ˆìŠ¤í…Œë¡¤ 198 mg/dLë¡œ ì •ìƒë²”ìœ„(<200 mg/dL) ë‚´.
     - LDL ì½œë ˆìŠ¤í…Œë¡¤ 115 mg/dL (ì •ìƒë²”ìœ„: <130 mg/dL)
     - HDL ì½œë ˆìŠ¤í…Œë¡¤ 55 mg/dL (ì—¬ì„± â‰¥50 mg/dL)
     - ì¤‘ì„±ì§€ë°© 140 mg/dL (ì •ìƒë²”ìœ„: <150 mg/dL)
   - ì´ìƒì§€ì§ˆí˜ˆì¦ ê´€ë ¨ ì†Œê²¬ ì—†ìŒ.

3. **í˜ˆì•¡í•™ ê²€ì‚¬**
   - í˜ˆìƒ‰ì†Œ(Hb) 12.6 g/dLë¡œ ì—¬ì„± ì •ìƒë²”ìœ„(12.0â€“16.0 g/dL)ì— í•´ë‹¹í•˜ë©° ë¹ˆí˜ˆ ì†Œê²¬ ì—†ìŒ.

4. **ìˆœí™˜ê¸°ê³„ ê²€ì‚¬**
   - í˜ˆì•• 135/88 mmHgë¡œ ì •ìƒë²”ìœ„(ìˆ˜ì¶•ê¸°í˜ˆì•• <130 mmHg, ì´ì™„ê¸°í˜ˆì•• <85 mmHg)ì— ê·¼ì ‘í•˜ì˜€ìœ¼ë©°, ê³ í˜ˆì•• ì „ë‹¨ê³„ ì£¼ì˜ ìš”ë§.

5. **ì‹ ì¥ê¸°ëŠ¥ ê²€ì‚¬**
   - í˜ˆì²­ í¬ë ˆì•„í‹°ë‹Œ(Cr) 1.5 mg/dLë¡œ ì •ìƒë²”ìœ„(0.7â€“1.2 mg/dL)ë¥¼ ìƒíšŒ.
   - eGFR 48 mL/min/1.73ã¡ë¡œ ë§Œì„± ì‹ ì¥ë³‘ ê¸°ì¤€(<60 mL/min/1.73ã¡)ì— í•´ë‹¹í•˜ë©°, ë§Œì„± ì‹ ì¥ë³‘ ì˜ì‹¬.
   - ìš”ë‹¨ë°± ê²€ì‚¬ ê²°ê³¼ ì–‘ì„±(1+)ìœ¼ë¡œ ë‹¨ë°±ë‡¨ ì†Œê²¬ ìˆìŒ.

6. **ê°„ê¸°ëŠ¥ ê²€ì‚¬**
   - AST 55 IU/L, ALT 62 IU/L, Î³-GTP 85 IU/Lë¡œ ëª¨ë‘ ì •ìƒë²”ìœ„(AST/ALT â‰¤40 IU/L, Î³-GTP â‰¤50 IU/L)ë¥¼ ìƒíšŒ.
   - ê°„ì¥ì§ˆí™˜ ê´€ë ¨ ì†Œê²¬: ì§€ì†ì  ê°„ê¸°ëŠ¥ ì´ìƒ ì˜ì‹¬.

7. **ì˜ìƒê²€ì‚¬**
   - í‰ë¶€ X-ray ê²€ì‚¬ìƒ íì•¼ ì²­ì •í•˜ë©° ì‹¬ì¥, í‰ê³½ êµ¬ì¡°ë¬¼ ë“± íŠ¹ì´ì†Œê²¬ ì—†ìŒ.

---

í™˜ìëŠ” ì‹ ì¥ê¸°ëŠ¥ ì €í•˜ ë° ê°„ê¸°ëŠ¥ ì´ìƒ ì†Œê²¬ì„ ë³´ì„. ì •ê¸°ì ì¸ ì¶”ì  ê´€ì°° ë° ìƒí™œìŠµê´€ ê°œì„ , ì‹ì´ìš”ë²•, ìš´ë™ ë“± ì ê·¹ì ì¸ ê´€ë¦¬ê°€ ìš”ë§ë¨.
"""

def return_json_for_test(): # í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜

    return test_data


def return_summary_for_test():

    temp = "ìš”ì•½"

    return temp

def return_explanation_for_test(): #í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜

    temp = """
ğŸ‘‹ ì•ˆë…•í•˜ì„¸ìš”, ê±´ê°•í•œë‹¤ëŒì¥ë‹˜! ê²€ì‚¬ ê²°ê³¼ë¥¼ ì‚´í´ë´¤ì–´ìš”. ê±±ì •í•˜ì§€ ë§ˆì„¸ìš”. í•¨ê»˜ ì°¨ê·¼ì°¨ê·¼ ì‚´í´ë³´ë„ë¡ í•´ìš”.

ğŸ“Œ ì£¼ìš” ì‚¬í•­: í˜ˆë‹¹, ì‹ ì¥ ê¸°ëŠ¥, ê°„ ê¸°ëŠ¥

ğŸ” ìì„¸í•œ ì„¤ëª…:

* í˜ˆë‹¹: ê³µë³µ í˜ˆë‹¹ì´ ë†’ì€ í¸ì´ì—ìš”. ì´ëŠ” í˜ˆë‹¹ì„ ì¡°ì ˆí•˜ëŠ” ë° ì£¼ì˜ê°€ í•„ìš”í•¨ì„ ì˜ë¯¸í•´ìš”. ê³¼ì¼, ì±„ì†Œì™€ ê°™ì€ ê±´ê°•í•œ íƒ„ìˆ˜í™”ë¬¼ì„ ì„ íƒí•˜ê³ , ê·œì¹™ì ì¸ ìš´ë™ì„ í†µí•´ í˜ˆë‹¹ì„ ê´€ë¦¬í•  ìˆ˜ ìˆì–´ìš”.
(ìƒëµ)

âœ… ìƒí™œìŠµê´€ íŒ:
(ìƒëµ)

"""
    return temp

def return_simple_explanation(API_KEY, file_path, health_info):
    # Step 1 Define the conversation for Solar LLM using the provided prompt for an easy summary
    messages = [
        {
            "role": "system",
            "content": (
                """You are MAGIC, a Korean, warm and friendly AI health coach.
                Your job is to gently explain a patient's health check-up results using friendly language.
                Focus only on what needs attention. Never use complex medical terms or diagnosis names.
                Explain in everyday language that is emotionally supportive and easy to understand.
                Use emojis to make the explanation more friendly and engaging.

                Input:

                Doctor's health check-up summary (written in Korean)
                Patient nickname (e.g., ìŠ¬ê¸°ë¡œìš´ê³ ì–‘ì´)
                Age group (e.g., 30ëŒ€), Gender (e.g., ì—¬ì„±)
                Output Format:
                    ğŸ‘‹ Greeting & Empathy (1 short paragraph)
                    Greet the patient using their nickname. Briefly mention youâ€™ve read their results and will explain gently.

                    ğŸ“Œ Health Summary (2â€“3 sentences max)
                    Summarize the main areas that need attention. Keep it short and focused.

                    ğŸ” Detailed Explanation (up to 3 areas)
                    For each issue:

                    What was found (in natural words)
                    Why it matters (soft explanation)
                    How to help the body (adjust food, exercise, or habits)
                    Use lifestyle examples that are appropriate to age/gender.
                    âœ… Lifestyle Tips (2â€“3 total)
                    MUST Consider patient's age and sex
                    Offer kind and simple suggestions on food, movement, or daily routines.

                    Examples should suit the patientâ€™s profile (age and sex):
                    Young woman â†’ ë–¡ë³¶ì´, ë§ˆë¼íƒ•, í™ˆíŠ¸
                    Older woman â†’ ë°˜ì°¬, ì‚°ì±…, ìš”ê°€
                    Young man â†’ ì¹˜í‚¨, ë¼ë©´, í—¬ìŠ¤
                    Older man â†’ ë“±ì‚°, ìœ ì‚°ì†Œ ìš´ë™
                    ğŸ’¬ Friendly Encouragement
                    End with comforting words to support the patient and encourage action.
                """
            )
        },
        {
            "role": "user",
            "content": (
                #f"Patient's nickname: {health_info['ë³„ëª…']}\n   "
                #f"Patient's age group: {health_info['ë‚˜ì´']}\n"
                #f"Patient's gender: {health_info['ì„±ë³„']}\n"
                f"Health check-up result: {json.dumps(health_info, ensure_ascii=False)}\n"
                #f"Brief summary of the health check-up result: {summary_professional}\n"

                "Please provide an easy-to-understand summary focusing on key aspects that need attention."
            )
        }
    ]
    
    try:
        # Step 2: Call the Solar LLM using the Upstage API client
        client = OpenAI(api_key=API_KEY, base_url="https://api.upstage.ai/v1")
        response = client.chat.completions.create(
            model="solar-pro",
            messages=messages
        )
        
        # Step 3: Extract the summary text from the response
        summary_text = response.choices[0].message.content
        return summary_text
    except Exception as e:
        # Return a fallback message if the API call fails
        print(f"Error in return_summary: {str(e)}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì•½ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."


def return_summary(API_KEY, file_path, health_info):
    # Step 1 Define the conversation for Solar LLM using the provided prompt for an easy summary
    messages = [
        {
            "role": "system",
            "content": (
                """You are MAGIC, a Korean, warm and friendly AI health coach.
                Your job is to gently explain a patient's health check-up results using friendly language.
                Focus only on what needs attention. Never use complex medical terms or diagnosis names.
                Explain in everyday language that is emotionally supportive and easy to understand.
                Use emojis to make the explanation more friendly and engaging.

                ê° í•­ëª©ì€ ì•„ë˜ì˜ ê°„ëµí•œ ê¸°ì¤€ì— ë”°ë¼ í‰ê°€í•´ì£¼ì„¸ìš” (ë°˜ëŒ€ìª½ì˜ ì €í•˜ ìˆ˜ì¹˜ë„ ë™ì¼í•œ ë‹¨ê³„ë¡œ ì ìš©):  
                - **ì²´ì§ˆëŸ‰ì§€ìˆ˜ (BMI):** ì •ìƒ 18.5â€“24.9, Mild High 25.0â€“29.9, Severe High â‰¥30.0  
                - **í—ˆë¦¬ë‘˜ë ˆ:** ë‚¨ì„± â€“ ì •ìƒ 80â€“89, Mild High 90â€“99, Severe High â‰¥100; ì—¬ì„± â€“ ì •ìƒ 70â€“84, Mild High 85â€“94, Severe High â‰¥95  
                - **í˜ˆì•• (Systolic/Diastolic):** ì •ìƒ 100â€“119/70â€“79, Mild High 120â€“139/80â€“89, Severe High â‰¥140/â‰¥90  
                - **í˜ˆìƒ‰ì†Œ:** ë‚¨ì„± â€“ ì •ìƒ 13.5â€“17.5, ì—¬ì„± â€“ ì •ìƒ 12.0â€“15.5; ë‚®ê±°ë‚˜ ë†’ìœ¼ë©´ ê°ê° Mild/Severe Low ë˜ëŠ” Highë¡œ íŒë‹¨  
                - **ê³µë³µí˜ˆë‹¹:** ì •ìƒ 70â€“99, Mild High 100â€“125, Severe High â‰¥126  
                - **ì´ì½œë ˆìŠ¤í…Œë¡¤:** ì •ìƒ 160â€“199, Mild High 200â€“239, Severe High â‰¥240  
                - **ê³ ë°€ë„ì½œë ˆìŠ¤í…Œë¡¤ (HDL):** ë‚¨ì„± â€“ ì •ìƒ 40â€“59, ì—¬ì„± â€“ ì •ìƒ 50â€“69; ë‚®ê±°ë‚˜ ë†’ìœ¼ë©´ ë‹¨ê³„ì— ë”°ë¼ í‰ê°€  
                - **ì¤‘ì„±ì§€ë°©:** ì •ìƒ 90â€“149, Mild High 150â€“199, Severe High â‰¥200  
                - **ì €ë°€ë„ì½œë ˆìŠ¤í…Œë¡¤ (LDL):** ì •ìƒ 90â€“119, Mild High 120â€“159, Severe High â‰¥160  
                - **í˜ˆì²­í¬ë ˆì•„í‹°ë‹Œ:** ë‚¨ì„± â€“ ì •ìƒ 0.7â€“1.3, ì—¬ì„± â€“ ì •ìƒ 0.6â€“1.1  
                - **eGFR:** ì •ìƒ 60â€“89; ë‚®ìœ¼ë©´ Mild/Severe Low, ë†’ìœ¼ë©´ Mild/Severe High  

                ì´ ìš”ì•½ì€ í™˜ìì™€ ëŒ€í™”í•  ë–„ ê³„ì† ê¸°ì–µí•  'ë‹¨ê¸° ê¸°ì–µ'ìœ¼ë¡œ ì‚¬ìš©ë  ê²ƒì…ë‹ˆë‹¤.
                """
            )
        },
        {
            "role": "user",
            "content": (
                #f"Patient's nickname: {health_info.get('ë³„ëª…', 'í™˜ì')}\n"
                f"Patient's age: {st.session_state.age}\n"
                f"Patient's gender: {st.session_state.gender}\n"
                f"Health check-up result: {json.dumps(health_info, ensure_ascii=False)}\n"
                "ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ê° í•­ëª©ë³„ ìœ„í—˜ë„ë¥¼ í‰ê°€í•˜ê³  í™˜ìê°€ ê°€ì¥ ì£¼ì˜í•´ì•¼ í•  ê±´ê°• ë¬¸ì œë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”."
            )
        }
    ]
    
    try:
        # Step 2: Call the Solar LLM using the Upstage API client
        client = OpenAI(api_key=API_KEY, base_url="https://api.upstage.ai/v1")
        response = client.chat.completions.create(
            model="solar-pro",
            messages=messages
        )
        
        # Step 3: Extract the summary text from the response
        summary_text = response.choices[0].message.content
        return summary_text
    except Exception as e:
        # Return a fallback message if the API call fails
        print(f"Error in return_summary: {str(e)}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì•½ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

# ì§„ë£Œê³¼ ì¶”ì²œ í•¨ìˆ˜ (ì¶”ì²œ ì‚¬ìœ ì™€ ì¶”ì²œ ì§„ë£Œê³¼ ë°˜í™˜)
def suggest_specialty(API_KEY, health_info, summary):
    llm = ChatUpstage(api_key=API_KEY, model="solar-pro")
    
    prompt_template = """
    ë‹¹ì‹ ì€ ì˜ë£Œ ì¸ê³µì§€ëŠ¥ ì±—ë´‡ MAGICì…ë‹ˆë‹¤. 
    í™˜ìì˜ <ê±´ê°•ê²€ì§„ ê²°ê³¼>ì™€ <ìš”ì•½ ì •ë³´>ë¥¼ ë¶„ì„í•´, ë‹¤ìŒ ì§„ë£Œê³¼ ì¤‘ ê°€ì¥ ì ì ˆí•œ ê³³ì„ 1ê³³ ì¶”ì²œí•˜ê±°ë‚˜, ì¶”ì²œí•˜ì§€ ì•ŠìŒ:
    
    - ê°€ì •ì˜í•™ê³¼
    - ë‚´ê³¼
    - í˜ˆì•¡ë‚´ê³¼
    - ì†Œí™”ê¸°ë‚´ê³¼
    - ë‚´ë¶„ë¹„ë‚´ê³¼
    - ì‹¬ì¥ë‚´ê³¼
    - ì‹ ì¥ë‚´ê³¼
    - í•´ë‹¹ì—†ìŒ
    
    ì¶”ì²œ ê¸°ì¤€
    * í•´ë‹¹ì—†ìŒ: ëª¨ë“  ê²ƒì´ ì •ìƒì¸ ê²½ìš° ì¶”ì²œí•œë‹¤.
    * ê°€ì •ì˜í•™ê³¼: ì²´ì¤‘ ì¦ê°€, ê²½ë¯¸í•˜ê±°ë‚˜ ê²½ê³„ì„± ìœ„í—˜ ì†Œê²¬, ë‹¨ì¼ ê±´ê°•ë¬¸ì œê°€ ì˜ì‹¬ë  ë•Œ, ë‹¤ì–‘í•œ ì§ˆí™˜ì´ ìˆìœ¼ë‚˜ ë³µí•©ì ì´ì§€ ì•Šì€ ê²½ìš°
    * ë‚´ê³¼: 
    	- í˜ˆì•¡ë‚´ê³¼: í˜ˆìƒ‰ì†Œ ìˆ˜ì¹˜ê°€ ë‚®ê±°ë‚˜ ë†’ì€ ê²½ìš° (ë¹ˆí˜ˆ ë˜ëŠ” ì í˜ˆêµ¬ ì¦ê°€ ë“±), ë°±í˜ˆêµ¬, í˜ˆì†ŒíŒ ìˆ˜ì¹˜ ì´ìƒ, ê¸°íƒ€ í˜ˆì•¡ ì´ìƒ ì†Œê²¬ì´ ìˆì„ ë•Œ
    	- ì‹ ì¥ë‚´ê³¼: ì‹ ì¥ê¸°ëŠ¥ì— ë¬¸ì œê°€ ìˆëŠ” ê²½ìš° (GFR ë‚®ìŒ, í¬ë ˆì•„ë‹Œ ìƒìŠ¹ ë“±)
    	- ì‹¬ì¥ë‚´ê³¼: ê³ í˜ˆì••ì¸ ê²½ìš° ìš°ì„ , ë˜ëŠ” í˜ˆì••ì— ë¬¸ì œê°€ ìˆëŠ” ê²½ìš° (ìˆ˜ì¶•ê¸° í˜ˆì•• ë˜ëŠ” ì´ì™„ê¸° í˜ˆì•• ë†’ìŒ, ìˆ˜ì¶•ê¸° í˜ˆì••ê³¼ ì´ì™„ê¸° í˜ˆì•• ì°¨ì´ê°€ í¼)
    	- ë‚´ë¶„ë¹„ë‚´ê³¼: í˜ˆë‹¹ì— ì´ìƒì´ ìˆëŠ” ê²½ìš°, í˜¹ì€ ì´ìƒì§€ì§ˆí˜ˆì¦ê³¼ í˜ˆë‹¹ì— ê²½ê³„ì„± ì˜ì‹¬ì†Œê²¬ì´ ìˆëŠ” ê²½ìš°, ì—¬ëŸ¬ ë‚´ë¶„ë¹„ ì§ˆí™˜ì´ ë³µí•©ì ìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” ê²½ìš° (ì˜ˆ: ë‹¹ë‡¨ + ê³ ì§€í˜ˆì¦ + ê³ í˜ˆì•• ë“±), ê°€ì •ì˜í•™ê³¼ì—ì„œ ë‹¤ë£¨ê¸° ì–´ë ¤ìš´ ë³µì¡ë„ì¼ ê²½ìš°
    	- ì†Œí™”ê¸°ë‚´ê³¼: ê°„ê¸°ëŠ¥ì— ë¬¸ì œê°€ ìˆëŠ” ê²½ìš° (ALT, AST, ì§€í‹°í”¼ ìƒìŠ¹ ë“±)
    	- ë‚´ê³¼: ì§ˆí™˜ì˜ ì˜ì‹¬ë˜ì§€ë§Œ, ì•ì„  ì§ˆí™˜ë“¤ì´ ì•„ë‹Œ ê²½ìš°.
    
    ì¶”ê°€ ì§€ì¹¨
    ê°„ê²°í•˜ê³  ëª…í™•í•œ ìš”ì•½ê³¼ í•¨ê»˜ ì§„ë£Œê³¼ë¥¼ ì¶”ì²œí•  ê²ƒ
    ë™ì¼ í™˜ìì—ê²Œ ë³µí•©ì ìœ¼ë¡œ ì—¬ëŸ¬ ì§ˆí™˜ì´ ë°œê²¬ë˜ì–´ë„, í˜¹ì€ íŒë‹¨ì´ ì• ë§¤í•œ ê²½ìš°ë¼ë„ ìœ„ ê¸°ì¤€ì„ í† ëŒ€ë¡œ ê°€ì¥ ì í•©í•œ ê³¼ë¥¼ ë°˜ë“œì‹œ í•˜ë‚˜ë§Œ ì¶”ì²œí•  ê²ƒ
    ê²€ì§„ ê²°ê³¼ê°€ ëª¨ë‘ ì •ìƒì´ë¼ë©´ "ì¶”ì²œ_ì§„ë£Œê³¼"ë¥¼ "í•´ë‹¹ì—†ìŒ"ìœ¼ë¡œ ì¶œë ¥í•  ê²ƒ 
    ì˜ˆì‹œ ì¶œë ¥ê³¼ ê°™ì´ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•  ê²ƒ
    
    ì˜ˆì‹œ: ì²´ì¤‘ ì¦ê°€, í˜ˆìƒ‰ì†Œ ìˆ˜ì¹˜ ì •ìƒ, ê³µë³µ í˜ˆë‹¹ ì•½ê°„ ë†’ìŒ (ê²½ê³„ ìˆ˜ì¤€)
    ì˜ˆì‹œ ì¶œë ¥:
    {{
    	"ì¶”ì²œ_ì‚¬ìœ ": "ì²´ì¤‘ ì¦ê°€ì™€ ê²½ê³„ ìˆ˜ì¤€ì˜ í˜ˆë‹¹ì€ ë¹„êµì  ê²½ë¯¸í•œ ì†Œê²¬ì´ë©°, ë‹¨ì¼ ë¬¸ì œ ìœ„ì£¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë¯€ë¡œ ê°€ì •ì˜í•™ê³¼ê°€ ì í•©í•©ë‹ˆë‹¤.",
    	"ì¶”ì²œ_ì§„ë£Œê³¼": "ê°€ì •ì˜í•™ê³¼"
    }}
    
    <ê±´ê°•ê²€ì§„ ê²°ê³¼>:
    {health_info}

    <ìš”ì•½ ì •ë³´>:
    {summary}
    """
    final_prompt = PromptTemplate.from_template(prompt_template)
    output_parser = StrOutputParser()

    chain = final_prompt | llm | output_parser
    response = chain.invoke({"health_info": health_info, "summary": summary})

    temp = json.loads(response)
    reason = temp['ì¶”ì²œ_ì‚¬ìœ ']
    specialty = temp['ì¶”ì²œ_ì§„ë£Œê³¼']
    
    return reason, specialty



# ê°€ê¹Œìš´ ë³‘ì› ì°¾ê¸°
def get_nearest_clinics(clinics_info, longitude, latitude, specialty, k):
    if specialty in ('ê°€ì •ì˜í•™ê³¼', 'ë‚´ê³¼'):
        df = clinics_info[clinics_info['ì§„ë£Œê³¼'] == specialty]
    else:
        df = clinics_info[clinics_info[specialty] == 1]
    
    coords = df[['ì¢Œí‘œ(X)', 'ì¢Œí‘œ(Y)']].values
    tree = KDTree(coords)
    target = np.array([longitude, latitude])
    distance, indicies = tree.query(target, k=k)
    
    return df.iloc[indicies] # df ë°˜í™˜ -> UI íŒŒì¼ì—ì„œ í™”ë©´ì— í‘œì‹œ
