import json
import requests
from bs4 import BeautifulSoup
from langchain_upstage import ChatUpstage
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import base64, json
from openai import OpenAI

def encode_image_to_base64(path):
    with open(path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")

def extract_information_from_image(API_KEY, file_path):
    # Encode the image
    encoded_image = encode_image_to_base64(file_path)
    
    # Define your schema (or use a pre-generated one)
    schema = {
        "type": "json_schema",
        "json_schema": {
            "name": "document_schema",
            "schema": {
                "type": "object",
                "properties": {
                    "í‚¤": {
                        "type": "number",
                        "description": "í‚¤ (cm)"
                    },
                    "ëª¸ë¬´ê²Œ": {
                        "type": "number",
                        "description": "ëª¸ë¬´ê²Œ (kg)"
                    },
                    "ì²´ì§ˆëŸ‰ì§€ìˆ˜": {
                        "type": "number",
                        "description": "ì²´ì§ˆëŸ‰ì§€ìˆ˜ (kg/ã¡)"
                    },
                    "í—ˆë¦¬ë‘˜ë ˆ": {
                        "type": "number",
                        "description": "í—ˆë¦¬ë‘˜ë ˆ (cm)"
                    },
                    "í˜ˆì••": {
                        "type": "string",
                        "description": "í˜ˆì•• (ìˆ˜ì¶•ê¸°/ì´ì™„ê¸°, mmHg)"
                    },
                    "í˜ˆìƒ‰ì†Œ": {
                        "type": "string",
                        "description": "ë¹ˆí˜ˆ ë“± í˜ˆìƒ‰ì†Œ (g/dL)"
                    },
                    "ë¹ˆí˜ˆ ì†Œê²¬": {
                        "type": "string",
                        "description": "ì •ìƒ/ë¹ˆí˜ˆ ì˜ì‹¬/ê¸°íƒ€ ì¤‘ ì²´í¬ëœ í•­ëª©"
                    },
                    "ê³µë³µí˜ˆë‹¹": {
                        "type": "string",
                        "description": "ë‹¹ë‡¨ë³‘ ê³µë³µí˜ˆë‹¹ (mg/dL)"
                    },
                    "ë‹¹ë‡¨ë³‘ ì†Œê²¬": {
                        "type": "string",
                        "description": "ì •ìƒ/ê³µë³µí˜ˆë‹¹ì¥ì•  ì˜ì‹¬/ìœ ì§ˆí™˜ì/ë‹¹ë‡¨ë³‘ ì˜ì‹¬ ì¤‘ ì²´í¬ëœ í•­ëª©"
                    },
                    "ì´ì½œë ˆìŠ¤í…Œë¡¤": {
                        "type": "string",
                        "description": "ì´ì½œë ˆìŠ¤í…Œë¡¤ (mg/dL)"
                    },
                    "ê³ ë°€ë„ì½œë ˆìŠ¤í…Œë¡¤": {
                        "type": "string",
                        "description": "ê³ ë°€ë„ ì½œë ˆìŠ¤í…Œë¡¤ (mg/dL)"
                    },
                    "ì¤‘ì„±ì§€ë°©": {
                        "type": "string",
                        "description": "ì¤‘ì„±ì§€ë°© (mg/dL)"
                    },
                    "ì €ë°€ë„ì½œë ˆìŠ¤í…Œë¡¤": {
                        "type": "string",
                        "description": "ì €ë°€ë„ ì½œë ˆìŠ¤í…Œë¡¤ (mg/dL)"
                    },
                    "ì´ìƒì§€ì§ˆí˜ˆì¦ ì†Œê²¬": {
                        "type": "string",
                        "description": "ì •ìƒ/ê³ ì½œë ˆìŠ¤í…Œë¡¤í˜ˆì¦ ì˜ì‹¬/ê³ ì¤‘ì„±ì§€ë°©í˜ˆì¦ ì˜ì‹¬/ë‚®ì€ HDL ì½œë ˆìŠ¤í…Œë¡¤ ì˜ì‹¬/ìœ ì§ˆí™˜ì ì¤‘ ì²´í¬ëœ í•­ëª©"
                    },
                    "í˜ˆì²­í¬ë ˆì•„í‹°ë‹Œ": {
                        "type": "string",
                        "description": "í˜ˆì²­ í¬ë ˆì•„í‹°ë‹Œ (mg/dL)"
                    },
                    "eGFR": {
                        "type": "string",
                        "description": "ì‹ ì‚¬êµ¬ì²´ì—¬ê³¼ìœ¨ (mL/min/1.73ã¡)"
                    },
                    "ì‹ ì¥ì§ˆí™˜ ì†Œê²¬": {
                        "type": "string",
                        "description": "ì •ìƒ/ì‹ ì¥ê¸°ëŠ¥ ì´ìƒ ì˜ì‹¬ ì¤‘ ì²´í¬ëœ í•­ëª©"
                    },
                    "AST": {
                        "type": "string",
                        "description": "AST (SGOT) (IU/L)"
                    },
                    "ALT": {
                        "type": "string",
                        "description": "ALT (SGPT) (IU/L)"
                    },
                    "ê°ë§ˆì§€í‹°í”¼": {
                        "type": "string",
                        "description": "ê°ë§ˆì§€í‹°í”¼ (Î³GTP) (IU/L)"
                    },
                    "ê°„ì¥ì§ˆí™˜": {
                        "type": "string",
                        "description": "ì •ìƒ/ê°„ê¸°ëŠ¥ ì´ìƒ ì˜ì‹¬ ì¤‘ ì²´í¬ëœ í•­ëª©"
                    },
                    "ìš”ë‹¨ë°±": {
                        "type": "string",
                        "description": "ì •ìƒ/ê²½ê³„/ë‹¨ë°±ë‡¨ ì˜ì‹¬ ì¤‘ ì²´í¬ëœ í•­ëª©"
                    },
                    "í‰ë¶€ì´¬ì˜": {
                        "type": "string",
                        "description": "ì •ìƒ/ë¹„í™œë™ì„± íê²°í•µ/íŠ¹ì • ì§ˆí™˜ ì˜ì‹¬/ê¸°íƒ€ ì†Œê²¬ ì¤‘ ì²´í¬ëœ í•­ëª©"
                    },
                    "ê³¼ê±°ë³‘ë ¥": {
                        "type": "string",
                        "description": "ê³¼ê±°ë³‘ë ¥ (ì˜ˆ: ì—†ìŒ)"
                    },
                    "ì•½ë¬¼ì¹˜ë£Œë³‘ë ¥": {
                        "type": "string",
                        "description": "ì•½ë¬¼ì¹˜ë£Œë³‘ë ¥ (ì˜ˆ: ì—†ìŒ)"
                    }
                },
                "required": [
                "í‚¤",
                "ëª¸ë¬´ê²Œ",
                "ì²´ì§ˆëŸ‰ì§€ìˆ˜",
                "í—ˆë¦¬ë‘˜ë ˆ",
                "í˜ˆì••",
                "í˜ˆìƒ‰ì†Œ",
                "ë¹ˆí˜ˆ ì†Œê²¬",
                "ê³µë³µí˜ˆë‹¹",
                "ë‹¹ë‡¨ë³‘ ì†Œê²¬",
                "ì´ì½œë ˆìŠ¤í…Œë¡¤",
                "ê³ ë°€ë„ì½œë ˆìŠ¤í…Œë¡¤",
                "ì¤‘ì„±ì§€ë°©",
                "ì €ë°€ë„ì½œë ˆìŠ¤í…Œë¡¤",
                "ì´ìƒì§€ì§ˆí˜ˆì¦ ì†Œê²¬",
                "í˜ˆì²­í¬ë ˆì•„í‹°ë‹Œ",
                "eGFR",
                "ì‹ ì¥ì§ˆí™˜ ì†Œê²¬",
                "AST",
                "ALT",
                "ê°ë§ˆì§€í‹°í”¼",
                "ê°„ì¥ì§ˆí™˜",
                "ìš”ë‹¨ë°±",
                "í‰ë¶€ì´¬ì˜",
                "ê³¼ê±°ë³‘ë ¥",
                "ì•½ë¬¼ì¹˜ë£Œë³‘ë ¥"
                ]
            }
        }
    }
    
    # Create an API client
    extract_client = OpenAI(api_key=API_KEY, base_url="https://api.upstage.ai/v1/information-extraction")
    
    # Call the extraction API
    extraction_response = extract_client.chat.completions.create(
        model="information-extract",
        messages=[{"role": "user", "content": [
            {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{encoded_image}"}}
        ]}],
        response_format=schema
    )
    
    # Parse the JSON result
    extracted_data = json.loads(extraction_response.choices[0].message.content)
    return extracted_data

# upstage request ì˜¤ë¥˜ í™•ì¸
def print_upstage_error(response):
    if 'error' in response.json().keys():
        return response.json()['error']

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_function(API_KEY, file_path):

    url = "https://api.upstage.ai/v1/document-digitization"
    headers = {"Authorization": f"Bearer {API_KEY}"}
    files = {"document": open(file_path, "rb")}
    data = {"ocr": "force", "base64_encoding": "['table']", "model": "document-parse"}
    response = requests.post(url, headers=headers, files=files, data=data)

    # upstage ì˜¤ë¥˜ í™•ì¸
    upstage_error = print_upstage_error(response)
    if upstage_error:
        return upstage_error
    
    # ë©”ì¸ ê¸°ëŠ¥
    contents_html = response.json()['content']['html']
    soup = BeautifulSoup(contents_html)
    text = soup.find(attrs = {'id': '20'}).text

    return text



# ê°œë°œìš© ì˜ˆì‹œ ë°ì´í„°
test_data = """
{
"ë‚˜ì´": 30ëŒ€,
"ë³„ëª…": ê±´ê°•í•œë‹¤ëŒì¥,
"ì„±ë³„": ì—¬ì„±,
"í‚¤": 158,
"ëª¸ë¬´ê²Œ": 65.4,
"ì²´ì§ˆëŸ‰ì§€ìˆ˜": 26.2,
"í—ˆë¦¬ë‘˜ë ˆ": 86.0,
"í˜ˆì••": "135/88 mmHg",
"í˜ˆìƒ‰ì†Œ": "12.6",
"ë¹ˆí˜ˆ ì†Œê²¬": "ì •ìƒ",
"ê³µë³µí˜ˆë‹¹": "108",
"ë‹¹ë‡¨ë³‘ ì†Œê²¬": "ê³µë³µí˜ˆë‹¹ì¥ì•  ì˜ì‹¬",
"ì´ì½œë ˆìŠ¤í…Œë¡¤": "198",
"ê³ ë°€ë„ì½œë ˆìŠ¤í…Œë¡¤": "55",
"ì¤‘ì„±ì§€ë°©": "140",
"ì €ë°€ë„ì½œë ˆìŠ¤í…Œë¡¤": "115",
"ì´ìƒì§€ì§ˆí˜ˆì¦ ì†Œê²¬": "ì •ìƒ",
"í˜ˆì²­í¬ë ˆì•„í‹°ë‹Œ": "1.5",
"eGFR": "48",
"ì‹ ì¥ì§ˆí™˜ ì†Œê²¬": "ë§Œì„± ì‹ ì¥ë³‘ ì˜ì‹¬",
"AST": "55",
"ALT": "62",
"ê°ë§ˆì§€í‹°í”¼": "85",
"ê°„ì¥ì§ˆí™˜": "ì§€ì†ì  ê°„ê¸°ëŠ¥ ì´ìƒ",
"ìš”ë‹¨ë°±": "ì–‘ì„±(1+)",
"í‰ë¶€ì´¬ì˜": "ì •ìƒ"
}
"""


def return_json_for_test(): # í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜

    return test_data

def return_json(API_KEY, file_path):
    # Instead of returning test data, use the real extraction function:
    return extract_information_from_image(API_KEY, file_path)


def return_summary_for_test(): #í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜

    temp = """
ğŸ‘‹ ì•ˆë…•í•˜ì„¸ìš”, ê±´ê°•í•œë‹¤ëŒì¥ë‹˜! ê²€ì‚¬ ê²°ê³¼ë¥¼ ì‚´í´ë´¤ì–´ìš”. ê±±ì •í•˜ì§€ ë§ˆì„¸ìš”. í•¨ê»˜ ì°¨ê·¼ì°¨ê·¼ ì‚´í´ë³´ë„ë¡ í•´ìš”.

ğŸ“Œ ì£¼ìš” ì‚¬í•­: í˜ˆë‹¹, ì‹ ì¥ ê¸°ëŠ¥, ê°„ ê¸°ëŠ¥

ğŸ” ìì„¸í•œ ì„¤ëª…:

* í˜ˆë‹¹: ê³µë³µ í˜ˆë‹¹ì´ ë†’ì€ í¸ì´ì—ìš”. ì´ëŠ” í˜ˆë‹¹ì„ ì¡°ì ˆí•˜ëŠ” ë° ì£¼ì˜ê°€ í•„ìš”í•¨ì„ ì˜ë¯¸í•´ìš”. ê³¼ì¼, ì±„ì†Œì™€ ê°™ì€ ê±´ê°•í•œ íƒ„ìˆ˜í™”ë¬¼ì„ ì„ íƒí•˜ê³ , ê·œì¹™ì ì¸ ìš´ë™ì„ í†µí•´ í˜ˆë‹¹ì„ ê´€ë¦¬í•  ìˆ˜ ìˆì–´ìš”.
(ìƒëµ)

âœ… ìƒí™œìŠµê´€ íŒ:
(ìƒëµ)

"""
    return temp

def return_summary(API_KEY, file_path):
    # Step 1: Extract health information from the image
    health_info = return_json(API_KEY, file_path)
    
    # Step 2: Define the conversation for Solar LLM using the provided prompt for an easy summary
    messages = [
        {
            "role": "system",
            "content": (
                "You are Dr. ì†Œë¼, a warm and friendly AI health coach.\n"
                "Your job is to gently explain a patient's health check-up results using soft and clear language.\n"
                "Focus only on what needs attention. Never use complex medical terms or diagnosis names.\n"
                "Explain in everyday language that is emotionally supportive and easy to understand."
            )
        },
        {
            "role": "user",
            "content": (
                f"Here is the health check-up result: {json.dumps(health_info, ensure_ascii=False)}\n"
                "Please provide an easy-to-understand summary focusing on key aspects that need attention."
            )
        }
    ]
    
    # Step 3: Call the Solar LLM using the Upstage API client
    client = OpenAI(api_key=API_KEY, base_url="https://api.upstage.ai/v1")
    response = client.chat.completions.create(
        model="solar-pro",
        messages=messages
    )
    
    # Extract the summary text from the response
    summary_text = response.choices[0].message['content']
    return summary_text


# ì§„ë£Œê³¼ ì¶”ì²œ í•¨ìˆ˜ (ì„ì‹œ)
def suggest_specialty(API_KEY, input_data):
    llm = ChatUpstage(api_key=API_KEY, model="solar-pro")
    
    prompt_template = """
ë‹¹ì‹ ì€ ì˜ë£Œ ì¸ê³µì§€ëŠ¥ ì±—ë´‡ MAGICì…ë‹ˆë‹¤. 
í™˜ìì˜ ê±´ê°•ê²€ì§„ ê²°ê³¼ë¥¼ ë¶„ì„í•´, ë‹¤ìŒ ì„¸ ê°€ì§€ ì§„ë£Œê³¼ ì¤‘ ê°€ì¥ ì ì ˆí•œ ê³³ì„ 1ê³³ ì¶”ì²œí•˜ê±°ë‚˜, ì¶”ì²œí•˜ì§€ ì•ŠìŒ:

1. ê°€ì •ì˜í•™ê³¼
2. ë‚´ê³¼
3. í˜ˆì•¡ë‚´ê³¼
4. í•´ë‹¹ì—†ìŒ

ì¶”ì²œ ê¸°ì¤€
ê°€ì •ì˜í•™ê³¼: ì²´ì¤‘ ì¦ê°€, ê²½ë¯¸í•˜ê±°ë‚˜ ê²½ê³„ì„± ìœ„í—˜ ì†Œê²¬, ë‹¨ì¼ ê±´ê°•ë¬¸ì œê°€ ì˜ì‹¬ë  ë•Œ, ë‹¤ì–‘í•œ ì§ˆí™˜ì´ ìˆìœ¼ë‚˜ ë³µí•©ì ì´ì§€ ì•Šì€ ê²½ìš°
ë‚´ê³¼: ê³ í˜ˆì••, ë‹¹ë‡¨ ë“± ëª…í™•í•œ ì§ˆë³‘ ì§„ë‹¨ì´ ìˆëŠ” ê²½ìš°, ì—¬ëŸ¬ ì§ˆí™˜ì´ ë³µí•©ì ìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” ê²½ìš° (ì˜ˆ: ê³ ì§€í˜ˆì¦ + ê³ í˜ˆì•• ë“±), ê°€ì •ì˜í•™ê³¼ì—ì„œ ë‹¤ë£¨ê¸° ì–´ë ¤ìš´ ë³µì¡ë„ì¼ ê²½ìš°

í˜ˆì•¡ë‚´ê³¼: í˜ˆìƒ‰ì†Œ ìˆ˜ì¹˜ê°€ ë‚®ê±°ë‚˜ ë†’ì€ ê²½ìš° (ë¹ˆí˜ˆ ë˜ëŠ” ì í˜ˆêµ¬ ì¦ê°€ ë“±), ë°±í˜ˆêµ¬, í˜ˆì†ŒíŒ ìˆ˜ì¹˜ ì´ìƒ, ê¸°íƒ€ í˜ˆì•¡ ì´ìƒ ì†Œê²¬ì´ ìˆì„ ë•Œ

ì¶”ê°€ ì§€ì¹¨
ê°„ê²°í•˜ê³  ëª…í™•í•œ ìš”ì•½ê³¼ í•¨ê»˜ ì§„ë£Œê³¼ë¥¼ ì¶”ì²œí•  ê²ƒ
ë™ì¼ í™˜ìì—ê²Œ ë³µí•©ì ìœ¼ë¡œ ì—¬ëŸ¬ ì§ˆí™˜ì´ ë°œê²¬ë˜ì–´ë„, í˜¹ì€ íŒë‹¨ì´ ì• ë§¤í•œ ê²½ìš°ë¼ë„ ìœ„ ê¸°ì¤€ì„ í† ëŒ€ë¡œ ê°€ì¥ ì í•©í•œ ê³¼ë¥¼ ë°˜ë“œì‹œ í•˜ë‚˜ë§Œ ì¶”ì²œí•  ê²ƒ
ê²€ì§„ ê²°ê³¼ê°€ ëª¨ë‘ ì •ìƒì´ë¼ë©´ "ì¶”ì²œ_ì§„ë£Œê³¼"ë¥¼ "í•´ë‹¹ì—†ìŒ"ìœ¼ë¡œ ì¶œë ¥í•  ê²ƒ 
ì˜ˆì‹œ ì¶œë ¥ê³¼ ê°™ì´ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•  ê²ƒ

ì˜ˆì‹œ: ì²´ì¤‘ ì¦ê°€, í˜ˆìƒ‰ì†Œ ìˆ˜ì¹˜ ì •ìƒ, ê³µë³µ í˜ˆë‹¹ ì•½ê°„ ë†’ìŒ (ê²½ê³„ ìˆ˜ì¤€)
ì˜ˆì‹œ ì¶œë ¥:
{
	"ê°„ëµí•œ_ìš”ì•½": "ì²´ì¤‘ ì¦ê°€ì™€ ê²½ê³„ ìˆ˜ì¤€ì˜ í˜ˆë‹¹ì€ ë¹„êµì  ê²½ë¯¸í•œ ì†Œê²¬ì´ë©°, ë‹¨ì¼ ë¬¸ì œ ìœ„ì£¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë¯€ë¡œ ê°€ì •ì˜í•™ê³¼ê°€ ì í•©í•©ë‹ˆë‹¤.",
	"ì¶”ì²œ_ì§„ë£Œê³¼": "ê°€ì •ì˜í•™ê³¼"
}
    """
    final_prompt = PromptTemplate.from_template(prompt_template)
    output_parser = StrOutputParser()

    chain = final_prompt | llm | output_parser
    response = chain.invoke({"input_data": input_data})
    
    return response
